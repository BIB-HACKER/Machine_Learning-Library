{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b306ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc249622",
   "metadata": {},
   "source": [
    "## Initialising the CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "327cbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e381e",
   "metadata": {},
   "source": [
    "## Step 1 - Convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fb0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cfef0",
   "metadata": {},
   "source": [
    "## Step 2 - Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff082d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007da110",
   "metadata": {},
   "source": [
    "## Adding a second convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6584da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d705b",
   "metadata": {},
   "source": [
    "## Step 3 - Flattening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1923ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a3643",
   "metadata": {},
   "source": [
    "## Step 4 - Full connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440acc53",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dense.__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m classifier\u001b[38;5;241m.\u001b[39madd(Dense(output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\dtensor\\utils.py:95\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layout:\n\u001b[0;32m     93\u001b[0m       layout_args[variable_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_layout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layout\n\u001b[1;32m---> 95\u001b[0m init_method(layer_instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layout_param_name, layout \u001b[38;5;129;01min\u001b[39;00m layout_args\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mTypeError\u001b[0m: Dense.__init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e6e71",
   "metadata": {},
   "source": [
    "## Compiling the CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523d0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092de16",
   "metadata": {},
   "source": [
    "## ####FITTING IMAGE TO CNN########### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a26cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    " \n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = (8000/32),\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = (2000/32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a679787",
   "metadata": {},
   "source": [
    "## ######Predicting the Image############ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a32602f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "225fca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cats', 1: 'dogs'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m resize(img,(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m)) \n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m----> 7\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_classes\u001b[49m(img)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print(prediction)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "class_labels = {v: k for k, v in training_set.class_indices.items()}\n",
    "print(class_labels)\n",
    "img = imread('pexels-photo-257540.jpeg') \n",
    "img = resize(img,(64,64)) \n",
    "img = np.expand_dims(img,axis=0) \n",
    "\n",
    "prediction = classifier.predict_classes(img)\n",
    "#print(prediction)\n",
    "if prediction[0][0]==1:\n",
    "    print(\"It is a dog\")\n",
    "elif prediction[0][0]==0:\n",
    "    print(\"It is a cat\")\n",
    "else:\n",
    "    print(\"i don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182af11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
